#!/bin/sh

TOME_MAX_CHANGE_ALLOWED=0.10

TOMELOGFILE=$1
YMDHMS=$2
FORCE=${3:-0}
RETRY_SEMAPHORE_FILE=/tmp/tome-log/retry-on-next-run

if [ -z "$YMDHMS" ]; then
  YMDHMS=$(date +"%Y_%m_%d_%H_%M_%S")
fi;

if [ -z "$TOMELOGFILE" ]; then
  TOMELOGFILE="${YMDHMS}.log"
fi;

# make sure there is a static site to sync
STATIC_COUNT=$(ls /var/www/html/ | wc -l)
if [ "$STATIC_COUNT" = "0" ]; then
  echo "NO SITE TO SYNC"
  exit 1;
fi;

export BUCKET_NAME=$(echo "$VCAP_SERVICES" | jq -r '.["s3"][]? | select(.name == "storage") | .credentials.bucket')
export AWS_DEFAULT_REGION=$(echo "$VCAP_SERVICES" | jq -r '.["s3"][]? | select(.name == "storage") | .credentials.region')
export AWS_ACCESS_KEY_ID=$(echo "${VCAP_SERVICES}" | jq -r '.["s3"][]? | select(.name == "storage") | .credentials.access_key_id')
export AWS_SECRET_ACCESS_KEY=$(echo "${VCAP_SERVICES}" | jq -r '.["s3"][]? | select(.name == "storage") | .credentials.secret_access_key')
export AWS_ENDPOINT=$(echo "${VCAP_SERVICES}" | jq -r '.["s3"][]? | select(.name == "storage") | .credentials.hostname')
if [ -z "$AWS_ENDPOINT" ] || [ "$AWS_ENDPOINT" == "null" ]; then
  export AWS_ENDPOINT=$(echo "${VCAP_SERVICES}" | jq -r '.["s3"][]? | select(.name == "storage") | .credentials.endpoint');
fi

# grab the cloudgov space we are hosted in
APP_SPACE=$(echo "$VCAP_APPLICATION" | jq -r '.space_name')
APP_SPACE=${APP_SPACE:-local}

# endpoint and ssl specifications only necessary on local for minio support
S3_EXTRA_PARAMS=""
if [ "${APP_SPACE}" = "local" ]; then
  S3_EXTRA_PARAMS="--endpoint-url https://$AWS_ENDPOINT --no-verify-ssl"
fi

# Use a unique dir for each run - just in case more than one of this is running
RENDER_DIR=/tmp/tome/$YMDHMS

if [ -d "$RENDER_DIR" ]; then
  rm -rf $RENDER_DIR
fi;
mkdir -p $RENDER_DIR

# copy from tome's output directory to our working directory RENDER_DIR
# RISK: tome's output diretory is not locked, mulitple processes could cause issues
cp -Rp /var/www/html/* $RENDER_DIR
cd $RENDER_DIR

mkdir -p /tmp/tome-log/
TOMELOG=/tmp/tome-log/$TOMELOGFILE
touch $TOMELOG

# Tome is failing to pull in these assets so we will pull them in ourself
echo "Add in any extra or missing files ... "
aws s3 cp --recursive s3://$BUCKET_NAME/cms/public/ $RENDER_DIR/s3/files/ --exclude "php/*" --exclude "*.gz" $S3_EXTRA_PARAMS 2>&1 | tee -a $TOMELOG
cp -rfp /var/www/web/themes/custom/usagov/fonts  $RENDER_DIR/themes/custom/usagov 2>&1 | tee -a $TOMELOG
cp -rfp /var/www/web/themes/custom/usagov/images $RENDER_DIR/themes/custom/usagov 2>&1 | tee -a $TOMELOG
cp -rfp /var/www/web/themes/custom/usagov/assets $RENDER_DIR/themes/custom/usagov 2>&1 | tee -a $TOMELOG

# Copy "webroot" assets (files like robots.txt and site.xml)
cp -rfp /var/www/webroot/* $RENDER_DIR/ 2>&1 | tee -a $TOMELOG

echo "Removing unwanted files ... "
rm -rf $RENDER_DIR/jsonapi/ 2>&1 | tee -a $TOMELOG
rm -rf $RENDER_DIR/node/ 2>&1 | tee -a $TOMELOG
rm -rf $RENDER_DIR/es/node/ 2>&1 | tee -a $TOMELOG


# duplicate the logic used by the bootstrap script to find the static site hostname
WWW_HOST=$(echo $VCAP_APPLICATION | jq -r '.["application_uris"][]' | grep 'www\.usa\.gov' | head -n 1)
WWW_HOST=${WWW_HOST:-$(echo $VCAP_APPLICATION | jq -r '.["application_uris"][]' | grep -v 'apps.internal' | grep beta | head -n 1)}

# add / at the end of the end
SITEMAP_FILE="$RENDER_DIR/sitemap.xml"
# Check if sitemap exists
if [ -f "$SITEMAP_FILE" ]; then
  echo "Updating sitemap ... "
  sed -i -e "s|/es\"/>|/es/\"/>|g" -e "s|/es</loc>|/es/</loc>|g" -e "s|<!--Generated by the Simple XML Sitemap Drupal module: https://drupal.org/project/simple_sitemap.-->||g" "$SITEMAP_FILE";
  # cat $SITEMAP_FILE
  diff $RENDER_DIR/sitemap_copy.xml $SITEMAP_FILE
else
  # Sitemap doesn't exists.
  echo "$SITEMAP_FILE does not exist."
fi
